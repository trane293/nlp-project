{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from itertools import islice # slicing for iterators\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import argparse # optparse is deprecated\n",
    "inp = 'data/hyp1-hyp2-ref'\n",
    "def sentences():\n",
    "    with open(inp) as f:\n",
    "        for pair in f:\n",
    "            yield [sentence.strip().split() for sentence in pair.split(' ||| ')]\n",
    "\n",
    "def exactMatching(h1, h2, bitstring_h1, bitstring_h2, alignments):\n",
    "    for ind_h1_word, word in enumerate(h1):\n",
    "        try:\n",
    "            ind_h2_word = h2.index(word)\n",
    "            if bitstring_h2[ind_h2_word] == 0:\n",
    "                # this is a candidate alignment\n",
    "                alignments.append((ind_h1_word, ind_h2_word))\n",
    "                bitstring_h2[ind_h2_word] = 1\n",
    "                bitstring_h1[ind_h1_word] = 1\n",
    "            else:\n",
    "                # this is not a candidate alignment\n",
    "                # search for next occurences\n",
    "                occurences = [i for i, j in enumerate(h2) if j == word]\n",
    "                for i in occurences:\n",
    "                    if bitstring_h2[i] == 0:\n",
    "                        alignments.append((ind_h1_word, i))\n",
    "                        bitstring_h2[i] = 1\n",
    "                        bitstring_h1[ind_h1_word] = 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    alignments = sorted(alignments, key=lambda x: x[0])\n",
    "\n",
    "    return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "def stemmerMatching(h1, h2, bitstring_h1, bitstring_h2, alignments):\n",
    "    un_matched_h1 = []\n",
    "    un_matched_h2 = []\n",
    "\n",
    "    for idx, word in enumerate(h1):\n",
    "        if bitstring_h1[idx] == 0:\n",
    "            un_matched_h1.append((idx, word))\n",
    "\n",
    "    for idx, word in enumerate(h2):\n",
    "        if bitstring_h2[idx] == 0:\n",
    "            un_matched_h2.append((idx, word))\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    stemmed_h1 = []\n",
    "    stemmed_h2 = []\n",
    "\n",
    "    if un_matched_h1 == [] or un_matched_h2 == []:\n",
    "#         print('no further alignment is possible..')\n",
    "        return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "    for ind_h1, word_h1 in un_matched_h1:\n",
    "        stemmed_h1.append((ind_h1, stemmer.stem(word_h1.decode('utf-8'))))\n",
    "\n",
    "    for ind_h2, word_h2 in un_matched_h2:\n",
    "        stemmed_h2.append((ind_h2, stemmer.stem(word_h2.decode('utf-8'))))\n",
    "\n",
    "    for id1, wd1 in stemmed_h1:\n",
    "        for id2, wd2 in stemmed_h2:\n",
    "            if wd1 == wd2 and (bitstring_h1[id1] == 0 and bitstring_h2[id2] == 0):\n",
    "                alignments.append((id1, id2))\n",
    "                bitstring_h1[id1] = 1\n",
    "                bitstring_h2[id2] = 1\n",
    "\n",
    "    return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "def synonymMatching(h1, h2, bitstring_h1, bitstring_h2, alignments):\n",
    "    un_matched_h1 = []\n",
    "    un_matched_h2 = []\n",
    "\n",
    "    for idx, word in enumerate(h1):\n",
    "        if bitstring_h1[idx] == 0:\n",
    "            un_matched_h1.append((idx, word))\n",
    "\n",
    "    for idx, word in enumerate(h2):\n",
    "        if bitstring_h2[idx] == 0:\n",
    "            un_matched_h2.append((idx, word))\n",
    "\n",
    "    if un_matched_h1 == [] or un_matched_h2 == []:\n",
    "#         print('no further alignment is possible..')\n",
    "        return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "    synonyms_h1 = []\n",
    "    synonyms_h2 = []\n",
    "    empty_set = set({})\n",
    "    for id1, wd1 in un_matched_h1:\n",
    "        wd1_synset = set(wn.synsets(wd1.decode('utf-8')))\n",
    "        for id2, wd2 in un_matched_h2:\n",
    "            if wd1_synset.intersection(wn.synsets(wd2.decode('utf-8'))) != empty_set and (bitstring_h1[id1] == 0 and bitstring_h2[id2] == 0):\n",
    "                alignments.append((id1, id2))\n",
    "                bitstring_h1[id1] = 1\n",
    "                bitstring_h2[id2] = 1\n",
    "\n",
    "    alignments = sorted(alignments, key=lambda x: x[0])\n",
    "\n",
    "    return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "def chunk(alignments):\n",
    "    chunks = []\n",
    "    for i in range(0, len(alignments)):\n",
    "        # start the chunk, but check if its already in previous chunk:\n",
    "\n",
    "        if i > 0 and alignments[i] in chunks[-1]:\n",
    "#             print('this alignment already belongs to previous chunk..moving on!')\n",
    "            continue\n",
    "\n",
    "#         print('starting chunk {}'.format(alignments[i]))\n",
    "        chunks.append([alignments[i]])\n",
    "\n",
    "        for j in range(i+1, len(alignments)):\n",
    "            if alignments[j-1][1] - alignments[j][1] == -1 and alignments[j-1][0] - alignments[j][0] == -1:\n",
    "                # append to current chunk\n",
    "#                 print('adding unigram alignment {} to previous chunk {}'.format(alignments[j], chunks[-1]))\n",
    "                chunks[-1].append(alignments[j])\n",
    "            else:\n",
    "#                 print('moving on to next alignment')\n",
    "                break\n",
    "\n",
    "    return chunks, len(chunks)\n",
    "\n",
    "def scoreMETEOR(h, ref, num_chunks, alignment, alpha=0.9, beta=3.0, gamma=0.5):\n",
    "    m = float(len(alignment))\n",
    "    r = float(len(ref))\n",
    "    t = float(len(h))\n",
    "    ch = float(num_chunks)\n",
    "\n",
    "    P = m / t\n",
    "    R = m / r\n",
    "\n",
    "    if P == 0.0 and R == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        F_mean = P*R / (alpha * P + (1 - alpha)*R)\n",
    "\n",
    "        frag = ch / m\n",
    "\n",
    "        penalty = gamma * (frag ** beta)\n",
    "\n",
    "        score = (1 - penalty) * F_mean\n",
    "\n",
    "        return score\n",
    "\n",
    "def main():\n",
    "    alignments_h1_ref = {}\n",
    "    alignments_h2_ref = {}\n",
    "    t = 0\n",
    "    # vals = []\n",
    "    num_chunks_h1 = {}\n",
    "    num_chunks_h2 = {}\n",
    "    score = {}\n",
    "\n",
    "    for h1, h2, ref in islice(sentences(), opts.num_sentences):\n",
    "        sys.stderr.write(str(t) + ' ')\n",
    "        bitstring_h1 = [0]*len(h1)\n",
    "        bitstring_ref = [0]*len(ref)\n",
    "        alignments_h1_ref[t] = []\n",
    "\n",
    "        h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = exactMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "        h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = stemmerMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "        h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = synonymMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "\n",
    "        _tm, num_chunks_h1[t] = chunk(alignments_h1_ref[t])\n",
    "\n",
    "        score_h1 = scoreMETEOR(h1, ref, num_chunks_h1[t], alignments_h1_ref[t], alpha=0.9, beta=3.0, gamma=0.5)\n",
    "\n",
    "        bitstring_h2 = [0]*len(h2)\n",
    "        bitstring_ref = [0]*len(ref)\n",
    "        alignments_h2_ref[t] = []\n",
    "\n",
    "        h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t] = exactMatching(h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t])\n",
    "        h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t] = stemmerMatching(h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t])\n",
    "        h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t] = synonymMatching(h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t])\n",
    "\n",
    "        _tm, num_chunks_h2[t] = chunk(alignments_h2_ref[t])\n",
    "\n",
    "        score_h2 = scoreMETEOR(h2, ref, num_chunks_h2[t], alignments_h2_ref[t], alpha=0.9, beta=3.0, gamma=0.5)\n",
    "\n",
    "        score[t] = [score_h1, score_h2]\n",
    "        print(1 if score[t][0] > score[t][1] else # \\begin{cases}\n",
    "                    (0 if score[t][0] == score[t][1]\n",
    "                        else -1), file=sys.stdout)\n",
    "        t += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreMETEOR_modified(h, ref, num_chunks, alignment, alpha=0.9, beta=3.0, gamma=0.5):\n",
    "    m = float(len(alignment))\n",
    "    r = float(len(ref))\n",
    "    t = float(len(h))\n",
    "    ch = float(num_chunks)\n",
    "    \n",
    "    print('m = {}, r = {}, t = {}, ch = {}'.format(m,r,t,ch))\n",
    "    P = m / t\n",
    "    R = m / r\n",
    "\n",
    "    print('P = {}, R = {}'.format(P, R))\n",
    "    \n",
    "    if P == 0.0 and R == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        F_mean = P*R / (alpha * P + (1 - alpha)*R)\n",
    "\n",
    "        frag = ch / m\n",
    "\n",
    "        penalty = gamma * (frag ** beta)\n",
    "\n",
    "        score = (1 - penalty) * F_mean\n",
    "        \n",
    "        print('F_mean = {}, frag = {}, penalty = {}, score = {}'.format(F_mean, frag, penalty, score))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_h1_ref = {}\n",
    "alignments_h2_ref = {}\n",
    "t = 0\n",
    "# vals = []\n",
    "num_chunks_h1 = {}\n",
    "num_chunks_h2 = {}\n",
    "score = {}\n",
    "\n",
    "h1 = 'the cat was sat on the mat'.split()\n",
    "ref = 'the cat sat on the mat'.split()\n",
    "\n",
    "bitstring_h1 = [0]*len(h1)\n",
    "bitstring_ref = [0]*len(ref)\n",
    "alignments_h1_ref[t] = []\n",
    "\n",
    "\n",
    "h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = exactMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = stemmerMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = synonymMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "\n",
    "_tm, num_chunks_h1[t] = chunk(alignments_h1_ref[t])\n",
    "\n",
    "score_h1 = scoreMETEOR(h1, ref, num_chunks_h1[t], alignments_h1_ref[t], alpha=0.9, beta=3.0, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from itertools import islice # slicing for iterators\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a generator and avoid loading all sentences into a list\n",
    "inp = 'data/hyp1-hyp2-ref'\n",
    "def sentences():\n",
    "    with open(inp) as f:\n",
    "        for pair in f:\n",
    "            yield [sentence.strip().split() for sentence in pair.split(' ||| ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactMatching(h1, h2, bitstring_h1, bitstring_h2, alignments):\n",
    "    for ind_h1_word, word in enumerate(h1):\n",
    "        try:\n",
    "            ind_h2_word = h2.index(word)\n",
    "            if bitstring_h2[ind_h2_word] == 0:\n",
    "                # this is a candidate alignment\n",
    "                alignments.append((ind_h1_word, ind_h2_word))\n",
    "                bitstring_h2[ind_h2_word] = 1\n",
    "                bitstring_h1[ind_h1_word] = 1\n",
    "            else:\n",
    "                # this is not a candidate alignment\n",
    "                # search for next occurences\n",
    "                occurences = [i for i, j in enumerate(h2) if j == word]\n",
    "                for i in occurences:\n",
    "                    if bitstring_h2[i] == 0:\n",
    "                        alignments.append((ind_h1_word, i))\n",
    "                        bitstring_h2[i] = 1\n",
    "                        bitstring_h1[ind_h1_word] = 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    alignments = sorted(alignments, key=lambda x: x[0])\n",
    "    \n",
    "    return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "def stemmerMatching(h1, h2, bitstring_h1, bitstring_h2, alignments):\n",
    "    un_matched_h1 = []\n",
    "    un_matched_h2 = []\n",
    "\n",
    "    for idx, word in enumerate(h1):\n",
    "        if bitstring_h1[idx] == 0:\n",
    "            un_matched_h1.append((idx, word))\n",
    "\n",
    "    for idx, word in enumerate(h2):\n",
    "        if bitstring_h2[idx] == 0:\n",
    "            un_matched_h2.append((idx, word))\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    stemmed_h1 = []\n",
    "    stemmed_h2 = []\n",
    "\n",
    "    if un_matched_h1 == [] or un_matched_h2 == []:\n",
    "#         print('no further alignment is possible..')\n",
    "        return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "    for ind_h1, word_h1 in un_matched_h1:\n",
    "        stemmed_h1.append((ind_h1, stemmer.stem(word_h1.decode('utf-8'))))\n",
    "\n",
    "    for ind_h2, word_h2 in un_matched_h2:\n",
    "        stemmed_h2.append((ind_h2, stemmer.stem(word_h2.decode('utf-8'))))\n",
    "\n",
    "    for id1, wd1 in stemmed_h1:\n",
    "        for id2, wd2 in stemmed_h2:\n",
    "            if wd1 == wd2 and (bitstring_h1[id1] == 0 and bitstring_h2[id2] == 0):\n",
    "                alignments.append((id1, id2))\n",
    "                bitstring_h1[id1] = 1\n",
    "                bitstring_h2[id2] = 1\n",
    "                \n",
    "    alignments = sorted(alignments, key=lambda x: x[0])\n",
    "    \n",
    "    return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "def synonymMatching(h1, h2, bitstring_h1, bitstring_h2, alignments):\n",
    "    un_matched_h1 = []\n",
    "    un_matched_h2 = []\n",
    "\n",
    "    for idx, word in enumerate(h1):\n",
    "        if bitstring_h1[idx] == 0:\n",
    "            un_matched_h1.append((idx, word))\n",
    "\n",
    "    for idx, word in enumerate(h2):\n",
    "        if bitstring_h2[idx] == 0:\n",
    "            un_matched_h2.append((idx, word))\n",
    "\n",
    "    if un_matched_h1 == [] or un_matched_h2 == []:\n",
    "#         print('no further alignment is possible..')\n",
    "        return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "    synonyms_h1 = []\n",
    "    synonyms_h2 = []\n",
    "\n",
    "    for id1, wd1 in un_matched_h1:\n",
    "        for id2, wd2 in un_matched_h2:\n",
    "            if set(wn.synsets(wd1.decode('utf-8'))).intersection(wn.synsets(wd2.decode('utf-8'))) != set({}) and (bitstring_h1[id1] == 0 and bitstring_h2[id2] == 0):\n",
    "                alignments.append((id1, id2))\n",
    "                bitstring_h1[id1] = 1\n",
    "                bitstring_h2[id2] = 1\n",
    "    \n",
    "    alignments = sorted(alignments, key=lambda x: x[0])\n",
    "    \n",
    "    return h1, h2, bitstring_h1, bitstring_h2, alignments\n",
    "\n",
    "def chunk(alignments):\n",
    "    chunks = []\n",
    "    for i in range(0, len(alignments)):\n",
    "        # start the chunk, but check if its already in previous chunk:\n",
    "\n",
    "        if i > 0 and alignments[i] in chunks[-1]:\n",
    "#             print('this alignment already belongs to previous chunk..moving on!')\n",
    "            continue\n",
    "\n",
    "#         print('starting chunk {}'.format(alignments[i]))\n",
    "        chunks.append([alignments[i]])\n",
    "\n",
    "        for j in range(i+1, len(alignments)):\n",
    "            if alignments[j-1][1] - alignments[j][1] == -1:\n",
    "                # append to current chunk\n",
    "#                 print('adding unigram alignment {} to previous chunk {}'.format(alignments[j], chunks[-1]))\n",
    "                chunks[-1].append(alignments[j])\n",
    "            else:\n",
    "#                 print('moving on to next alignment')\n",
    "                break\n",
    "                \n",
    "    return chunks, len(chunks)\n",
    "\n",
    "def scoreMETEOR(h, ref, num_chunks, alignment, alpha=0.9, beta=3.0, gamma=0.5):\n",
    "    m = float(len(alignment))\n",
    "    r = float(len(ref))\n",
    "    t = float(len(h))\n",
    "    ch = float(num_chunks)\n",
    "    \n",
    "    P = m / t\n",
    "    R = m / r\n",
    "\n",
    "    F_mean = P*R / (alpha * P + (1 - alpha)*R)\n",
    "\n",
    "    frag = ch / m\n",
    "\n",
    "    penalty = gamma * (frag ** beta)\n",
    "\n",
    "    score = (1 - penalty) * F_mean\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_h1_ref = {}\n",
    "alignments_h2_ref = {}\n",
    "t = 0\n",
    "# vals = []\n",
    "num_chunks_h1 = {}\n",
    "num_chunks_h2 = {}\n",
    "score = {}\n",
    "for h1, h2, ref in islice(sentences(), 5):\n",
    "#     vals.append((h1, h2, ref))\n",
    "    bitstring_h1 = [0]*len(h1)\n",
    "    bitstring_ref = [0]*len(ref)\n",
    "    alignments_h1_ref[t] = []\n",
    "    \n",
    "    h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = exactMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "    h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = stemmerMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])\n",
    "    h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t] = synonymMatching(h1, ref, bitstring_h1, bitstring_ref, alignments_h1_ref[t])    \n",
    "    \n",
    "    _tm, num_chunks_h1[t] = chunk(alignments_h1_ref[t])\n",
    "    \n",
    "    score_h1 = scoreMETEOR(h1, ref, num_chunks_h1[t], alignments_h1_ref[t], alpha=0.9, beta=3.0, gamma=0.5)\n",
    "    \n",
    "    bitstring_h2 = [0]*len(h2)\n",
    "    bitstring_ref = [0]*len(ref)\n",
    "    alignments_h2_ref[t] = []\n",
    "    \n",
    "    h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t] = exactMatching(h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t])\n",
    "    h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t] = stemmerMatching(h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t])\n",
    "    h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t] = synonymMatching(h2, ref, bitstring_h2, bitstring_ref, alignments_h2_ref[t])    \n",
    "    \n",
    "    _tm, num_chunks_h2[t] = chunk(alignments_h2_ref[t])\n",
    "    \n",
    "    score_h2 = scoreMETEOR(h2, ref, num_chunks_h2[t], alignments_h2_ref[t], alpha=0.9, beta=3.0, gamma=0.5)\n",
    "    \n",
    "    score[t] = [score_h1, score_h2]\n",
    "    t += 1\n",
    "    \n",
    "for scores in score:\n",
    "    print(1 if scores[0] > scores[1] else # \\begin{cases}\n",
    "                (0 if scores[0] == scores[1]\n",
    "                    else -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806451612903227"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = ['They', 'are', 'looking', 'for', 'alternatives', 'in', 'the', 'cities']\n",
    "r = ['Looking', 'for', 'alternatives', 'in', 'the', 'cities']\n",
    "scoreMETEOR(h, r, num_chunks_h2[0], alignments_h2_ref[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['They', 'are', 'looking', 'for', 'alternatives', 'in', 'cities'],\n",
       " ['They', 'are', 'looking', 'for', 'alternatives', 'in', 'the', 'cities'],\n",
       " ['Looking', 'for', 'alternatives', 'in', 'the', 'cities'])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0), (3, 1), (4, 2), (5, 3), (6, 4), (7, 5)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments_h2_ref[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chunks_h2[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chunks_h2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
