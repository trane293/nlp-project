{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:orange'> Modelling Chinese Word Segmentation as Sequence to Sequence Prediction Problem </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Green'> Testing Pre-Trained Models Notebook</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "model = load_model('/home/asa224/Desktop/students_less_asa224/Test Folder on Less/model_epoch3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateInputWordFile(filename='/local-scratch/asa224/input'):\n",
    "    \"\"\"\n",
    "    The function generates the word file, similar to the count_1w.txt file provided by Prof. Anoop\n",
    "    \n",
    "    The output of the file can be used to parse the characters, and is an input to the \n",
    "    generateTupleList() function as well. \n",
    "    \n",
    "    INPUT: Input to this function is the training text file. \n",
    "    \n",
    "    \"\"\"\n",
    "    with(open(filename, 'rb')) as f:\n",
    "        word_file_1M = open('/local-scratch/input_word_file', 'wb')\n",
    "        for line in f:\n",
    "            line = unicode(line, 'utf-8')\n",
    "            line = line.replace('\\n', '')\n",
    "            for word in line:\n",
    "                word_file_1M.write(word.encode('utf-8') + '\\t'.encode('utf-8') + str(0).encode('utf-8') +\\\n",
    "                                           '\\n'.encode('utf-8'))\n",
    "        f.close()\n",
    "    word_file_1M.close()\n",
    "    \n",
    "    \n",
    "def generateTupleList(filename='/local-scratch/asa224/word_file_1M'):\n",
    "    \"\"\"\n",
    "    This function is similar to the above function in the sense that it assigns labels to each\n",
    "    character in the training set. The function returns a list of tuples, in which each tuple\n",
    "    contains a single character and its corresponding label. \n",
    "    \n",
    "    INPUT: Input to this function is a WORD FILE generated by generateWordFile(filename) function. \n",
    "    \n",
    "    Use this function in conjunction with nGramSequenceGenerator(labelledlist, n) to create a\n",
    "    training set with constant sequence size, which does not require paddings. \n",
    "    \"\"\"\n",
    "    with(open(filename, 'rb')) as f:\n",
    "        label = []\n",
    "        for line in f:\n",
    "            word, count = line.split('\\t')\n",
    "\n",
    "            # making sure the parsing is going fine\n",
    "            assert int(count) == 0\n",
    "\n",
    "            word = unicode(word, 'utf-8')\n",
    "            if len(word) == 1:\n",
    "                label.append((word[0], 3))\n",
    "            else:\n",
    "                for i, character in enumerate(word):\n",
    "                    if i == 0: # this is the first letter\n",
    "                        label.append((character, 0))\n",
    "                    elif i == (len(word) - 1): # this is the last letter\n",
    "                        label.append((character, 2))\n",
    "                    else: # this is somewhere in the middle\n",
    "                        label.append((character, 1))\n",
    "\n",
    "        f.close()\n",
    "        return label\n",
    "    \n",
    "def nGramSequenceGenerator(labelledlist, n):\n",
    "    \"\"\"\n",
    "    Takes as input the label list of tuples generated by the code above. \n",
    "    The function generates sequence of size \"n\" from the given list. \n",
    "    \"\"\"\n",
    "    count = len(labelledlist)/n\n",
    "    ngrammedlist = []\n",
    "    for i in range(count):\n",
    "        ngrammedlist.append( labelledlist[i*n : (i+1)*n])\n",
    "    return ngrammedlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateInputWordFile(filename='/home/asa224/Desktop/students_asa224/NLP Work/assignments/segmenter/data/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = generateTupleList(filename='/local-scratch/input_word_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dict = pickle.load( open( \"orig_dict.p\", \"rb\" ) )\n",
    "ret_dict = pickle.load( open( \"ret_dict.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[]]\n",
    "count = 0\n",
    "for i in range(0, len(final_input)): # iterate over the whole dataset\n",
    "    for j in range(0, len(final_input[i])): # iterate over the current sentence\n",
    "        try:\n",
    "            x[i].append(orig_dict[final_input[i][j][0]])\n",
    "        except KeyError:\n",
    "            x[i].append(np.random.choice(orig_dict.values()))\n",
    "            count += 1\n",
    "    x.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the prediction process, and write data to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open('./output_rnn', 'wb')\n",
    "for seq in x[:-1]:\n",
    "    pred_labels = model.predict_classes(np.array(seq).reshape(1,len(seq)))\n",
    "    # get the class label\n",
    "    \n",
    "    for num in range(0, len(pred_labels[0])):\n",
    "        char = seq[num]\n",
    "        if pred_labels[0][num] >= 2:\n",
    "#             print('writing {}'.format(ret_dict[char].encode('utf-8')))\n",
    "            out_file.write(ret_dict[char].encode('utf-8') + ' '.encode('utf-8'))\n",
    "        else:\n",
    "            out_file.write(ret_dict[char].encode('utf-8'))\n",
    "    \n",
    "#     out_file.write('\\n'.encode('utf-8'))\n",
    "    \n",
    "out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
